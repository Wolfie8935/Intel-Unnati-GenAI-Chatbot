{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8859251,"sourceType":"datasetVersion","datasetId":5333581}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Creating environment","metadata":{}},{"cell_type":"code","source":"!pip install intel-extension-for-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T10:37:30.002268Z","iopub.execute_input":"2024-07-08T10:37:30.002962Z","iopub.status.idle":"2024-07-08T10:37:47.549595Z","shell.execute_reply.started":"2024-07-08T10:37:30.002926Z","shell.execute_reply":"2024-07-08T10:37:47.548642Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting intel-extension-for-transformers\n  Downloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (21.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (1.26.4)\nCollecting schema (from intel-extension-for-transformers)\n  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (6.0.1)\nCollecting neural-compressor (from intel-extension-for-transformers)\n  Downloading neural_compressor-2.6-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from intel-extension-for-transformers) (4.41.2)\nRequirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (1.2.14)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (4.10.0.82)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (2.2.1)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (9.5.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (3.9.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (5.9.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (9.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (2.32.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from neural-compressor->intel-extension-for-transformers) (1.2.2)\nCollecting pycocotools (from neural-compressor->intel-extension-for-transformers)\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->intel-extension-for-transformers) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (0.23.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->intel-extension-for-transformers) (4.66.4)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.13->neural-compressor->intel-extension-for-transformers) (1.14.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers->intel-extension-for-transformers) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers->intel-extension-for-transformers) (4.9.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->neural-compressor->intel-extension-for-transformers) (2023.4)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prettytable->neural-compressor->intel-extension-for-transformers) (0.2.13)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->neural-compressor->intel-extension-for-transformers) (3.7.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->neural-compressor->intel-extension-for-transformers) (2024.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->neural-compressor->intel-extension-for-transformers) (3.2.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel-extension-for-transformers) (1.4.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->neural-compressor->intel-extension-for-transformers) (1.16.0)\nDownloading intel_extension_for_transformers-1.4.2-cp310-cp310-manylinux_2_28_x86_64.whl (45.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading neural_compressor-2.6-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\nDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: schema, pycocotools, neural-compressor, intel-extension-for-transformers\nSuccessfully installed intel-extension-for-transformers-1.4.2 neural-compressor-2.6 pycocotools-2.0.8 schema-0.7.7\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/intel/intel-extension-for-transformers.git\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:37:47.551594Z","iopub.execute_input":"2024-07-08T10:37:47.551876Z","iopub.status.idle":"2024-07-08T10:38:44.312608Z","shell.execute_reply.started":"2024-07-08T10:37:47.551849Z","shell.execute_reply":"2024-07-08T10:38:44.311647Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'intel-extension-for-transformers'...\nremote: Enumerating objects: 1679820, done.\u001b[K\nremote: Counting objects: 100% (114468/114468), done.\u001b[K\nremote: Compressing objects: 100% (13186/13186), done.\u001b[K\nremote: Total 1679820 (delta 61835), reused 111442 (delta 59129), pack-reused 1565352\u001b[K\nReceiving objects: 100% (1679820/1679820), 593.81 MiB | 31.82 MiB/s, done.\nResolving deltas: 100% (897751/897751), done.\nUpdating files: 100% (3216/3216), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:38:44.314270Z","iopub.execute_input":"2024-07-08T10:38:44.314865Z","iopub.status.idle":"2024-07-08T10:41:54.043205Z","shell.execute_reply.started":"2024-07-08T10:38:44.314823Z","shell.execute_reply":"2024-07-08T10:41:54.042090Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Looking in indexes: https://pypi.org/simple, https://pytorch-extension.intel.com/release-whl/stable/cpu/us/\nCollecting accelerate==0.28.0 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 2))\n  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\nCollecting cchardet (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 3))\n  Downloading cchardet-2.1.7.tar.gz (653 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.6/653.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting einops (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 4))\n  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\nCollecting evaluate (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 5))\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 6)) (0.108.0)\nCollecting fschat==0.2.32 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7))\n  Downloading fschat-0.2.32-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 8)) (0.23.2)\nCollecting intel_extension_for_pytorch==2.3.0 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 9))\n  Downloading https://intel-extension-for-pytorch.s3.amazonaws.com/ipex_stable/cpu/./intel_extension_for_pytorch-2.3.0%2Bcpu-cp310-cp310-linux_x86_64.whl (98.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lm-eval==0.4.2 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading lm_eval-0.4.2-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: neural-compressor in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (2.6)\nCollecting neural_speed==1.0a0 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 12))\n  Downloading neural_speed-1.0a0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.3 kB)\nCollecting numpy==1.23.5 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 13))\n  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\nCollecting oneccl_bind_pt (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 14))\n  Downloading https://intel-extension-for-pytorch.s3.amazonaws.com/ipex_stable/cpu/./oneccl_bind_pt-2.3.0%2Bcpu-cp310-cp310-linux_x86_64.whl (41.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting optimum (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 15))\n  Downloading optimum-1.21.2-py3-none-any.whl.metadata (19 kB)\nCollecting optimum-intel (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 16))\n  Downloading optimum_intel-1.18.0-py3-none-any.whl.metadata (16 kB)\nCollecting peft==0.6.2 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 17))\n  Downloading peft-0.6.2-py3-none-any.whl.metadata (23 kB)\nCollecting pydantic==1.10.13 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 18))\n  Downloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 19)) (1.0.0)\nCollecting python-multipart (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 20))\n  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\nCollecting rouge_score (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 21))\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting sacremoses (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 22))\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nCollecting shortuuid (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 23))\n  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 24)) (0.32.0.post1)\nCollecting tiktoken==0.4.0 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 25))\n  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\nCollecting torch==2.3.0 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nCollecting torchaudio==2.3.0 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 27))\n  Downloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\nRequirement already satisfied: transformers>=4.35.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 28)) (4.41.2)\nCollecting transformers_stream_generator (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 29))\n  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 30)) (0.25.0)\nCollecting yacs (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 31))\n  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 2)) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 2)) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 2)) (6.0.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 2)) (0.4.3)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (3.9.1)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (0.27.0)\nCollecting markdown2[all] (from fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7))\n  Downloading markdown2-2.4.13-py2.py3-none-any.whl.metadata (2.0 kB)\nCollecting nh3 (from fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7))\n  Downloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (3.0.42)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (2.32.3)\nRequirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (13.7.0)\nRequirement already satisfied: datasets>=2.16.0 in /opt/conda/lib/python3.10/site-packages (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (2.19.2)\nCollecting jsonlines (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (2.10.0)\nRequirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (2.12.0)\nCollecting pytablewriter (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\nCollecting sacrebleu>=1.5.0 (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (1.2.2)\nCollecting sqlitedict (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tqdm-multiprocess (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (0.19.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (0.3.8)\nCollecting word2number (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading word2number-1.1.zip (9.7 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (10.2.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.6.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 17)) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.13->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 18)) (4.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.4.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 25)) (2023.12.25)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26)) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26)) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26)) (2024.3.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.3.0 (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26))\n  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 5)) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 5)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 5)) (0.70.16)\nRequirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (1.2.14)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (4.10.0.82)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (9.5.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (3.9.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (9.0.0)\nRequirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (0.7.7)\nRequirement already satisfied: pycocotools in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (2.0.8)\nCollecting coloredlogs (from optimum->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 15))\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 16)) (0.2.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 16)) (69.0.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 16)) (1.11.4)\nRequirement already satisfied: onnx in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 16)) (1.16.1)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 21)) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 21)) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 21)) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 22)) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 22)) (1.4.2)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 24)) (4.2.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 28)) (0.19.1)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 30)) (0.14.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 24)) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 24)) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 24)) (1.2.0)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.16.0->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (0.6)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from deprecated>=1.2.13->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (1.14.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.28.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 2)) (3.1.1)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.0->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (2.17.2)\nCollecting portalocker (from sacrebleu>=1.5.0->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading portalocker-2.10.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (5.2.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10)) (3.2.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]<4.43.0,>=4.26.0->optimum->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 15)) (3.20.3)\nCollecting humanfriendly>=9.1 (from coloredlogs->optimum->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 15))\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (1.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26)) (2.1.3)\nCollecting wavedrom (from markdown2[all]->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7))\n  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 5)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 5)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 5)) (2023.4)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (3.7.5)\nCollecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\nCollecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\nCollecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading pathvalidate-3.2.0-py3-none-any.whl.metadata (11 kB)\nCollecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\nCollecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 26)) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7)) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 11)) (1.4.5)\nCollecting chardet<6,>=3.0.4 (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval==0.4.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 10))\n  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\nCollecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.32->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements_cpu.txt (line 7))\n  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\nDownloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fschat-0.2.32-py3-none-any.whl (211 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.4/211.4 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lm_eval-0.4.2-py3-none-any.whl (1.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading neural_speed-1.0a0-cp310-cp310-manylinux_2_28_x86_64.whl (23.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading peft-0.6.2-py3-none-any.whl (174 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchaudio-2.3.0-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum-1.21.2-py3-none-any.whl (424 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.7/424.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading optimum_intel-1.18.0-py3-none-any.whl (223 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.0/224.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\nDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nDownloading nh3-0.2.18-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m769.2/769.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\nDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\nDownloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\nDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\nDownloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\nDownloading typepy-1.3.2-py3-none-any.whl (31 kB)\nDownloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading portalocker-2.10.0-py3-none-any.whl (18 kB)\nDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: cchardet, rouge_score, transformers_stream_generator, sqlitedict, word2number, wavedrom\n  Building wheel for cchardet (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cchardet: filename=cchardet-2.1.7-cp310-cp310-linux_x86_64.whl size=143397 sha256=d4c6776e014ba174692ef6ad0027af1afdbaa2aff665f6b40edad84894815623\n  Stored in directory: /root/.cache/pip/wheels/ee/e0/ab/e01326f15c59438d080b1496dbab8091e952ec72f35e3c437e\n  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=2a1ed45abf1f4dbffddb215d08995a82a0657e2b1e360bbf60e7fbeca242840f\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12424 sha256=6b2c1b02402ea49f3391a8a61cec1da2d99be78a4b7fe2ae8edc61812df49388\n  Stored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\n  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=660589efeede8710a005b0435040457a98c02ad105984d388bbdff8a2cdc73f0\n  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=b46e1717d0776d05f0a720edaa2ebc41320fc12b3b6d422f8e3934b4577a7969\n  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n  Building wheel for wavedrom (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=310f836946b5f9b0eda66f9a3436f4e29e3eddaa39c95b45cc99570cb3cd2ea9\n  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\nSuccessfully built cchardet rouge_score transformers_stream_generator sqlitedict word2number wavedrom\nInstalling collected packages: word2number, sqlitedict, oneccl_bind_pt, nh3, cchardet, yacs, triton, tqdm-multiprocess, tcolorpy, svgwrite, shortuuid, sacremoses, python-multipart, pydantic, portalocker, pathvalidate, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, neural_speed, markdown2, jsonlines, humanfriendly, einops, chardet, wavedrom, tiktoken, sacrebleu, rouge_score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, mbstrdecoder, intel_extension_for_pytorch, coloredlogs, typepy, nvidia-cusolver-cu12, torch, fschat, transformers_stream_generator, torchaudio, evaluate, DataProperty, accelerate, tabledata, peft, optimum, pytablewriter, optimum-intel, lm-eval\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.5.3\n    Uninstalling pydantic-2.5.3:\n      Successfully uninstalled pydantic-2.5.3\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\n  Attempting uninstall: torchaudio\n    Found existing installation: torchaudio 2.1.2\n    Uninstalling torchaudio-2.1.2:\n      Successfully uninstalled torchaudio-2.1.2\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.30.1\n    Uninstalling accelerate-0.30.1:\n      Successfully uninstalled accelerate-0.30.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-nlp 0.12.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\nalbumentations 1.4.0 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 14.0.2 which is incompatible.\nchex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\npyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\npylibraft 24.4.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\nrmm 24.4.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.3 which is incompatible.\ntensorstore 0.1.60 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\nxarray 2024.5.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.6.4 requires pydantic>=2, but you have pydantic 1.10.13 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed DataProperty-1.0.1 accelerate-0.28.0 cchardet-2.1.7 chardet-5.2.0 coloredlogs-15.0.1 einops-0.8.0 evaluate-0.4.2 fschat-0.2.32 humanfriendly-10.0 intel_extension_for_pytorch-2.3.0+cpu jsonlines-4.0.0 lm-eval-0.4.2 markdown2-2.4.13 mbstrdecoder-1.1.3 neural_speed-1.0a0 nh3-0.2.18 numpy-1.23.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 oneccl_bind_pt-2.3.0+cpu optimum-1.21.2 optimum-intel-1.18.0 pathvalidate-3.2.0 peft-0.6.2 portalocker-2.10.0 pydantic-1.10.13 pytablewriter-1.2.0 python-multipart-0.0.9 rouge_score-0.1.2 sacrebleu-2.4.2 sacremoses-0.1.1 shortuuid-1.0.13 sqlitedict-2.1.0 svgwrite-1.4.3 tabledata-1.3.3 tcolorpy-0.1.6 tiktoken-0.4.0 torch-2.3.0 torchaudio-2.3.0 tqdm-multiprocess-0.0.11 transformers_stream_generator-0.0.5 triton-2.3.0 typepy-1.3.2 wavedrom-2.0.3.post3 word2number-1.1 yacs-0.1.8\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:41:54.045674Z","iopub.execute_input":"2024-07-08T10:41:54.045970Z","iopub.status.idle":"2024-07-08T10:42:25.240920Z","shell.execute_reply.started":"2024-07-08T10:41:54.045942Z","shell.execute_reply":"2024-07-08T10:42:25.239812Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 1)) (0.28.0)\nRequirement already satisfied: cchardet in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 2)) (2.1.7)\nRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 3)) (0.8.0)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (0.4.2)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 5)) (0.108.0)\nCollecting fschat==0.2.35 (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6))\n  Downloading fschat-0.2.35-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 7)) (0.23.2)\nRequirement already satisfied: intel_extension_for_pytorch==2.3.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 8)) (2.3.0+cpu)\nRequirement already satisfied: lm-eval in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (0.4.2)\nRequirement already satisfied: neural-compressor in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (2.6)\nRequirement already satisfied: neural_speed==1.0a0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 11)) (1.0a0)\nRequirement already satisfied: numpy==1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 12)) (1.23.5)\nRequirement already satisfied: onnx>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 13)) (1.16.1)\nRequirement already satisfied: optimum in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 14)) (1.21.2)\nRequirement already satisfied: optimum-intel in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 15)) (1.18.0)\nRequirement already satisfied: peft==0.6.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 16)) (0.6.2)\nRequirement already satisfied: pydantic==1.10.13 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 17)) (1.10.13)\nRequirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 18)) (1.0.0)\nRequirement already satisfied: python-multipart in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 19)) (0.0.9)\nRequirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 20)) (0.1.2)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 21)) (0.1.1)\nRequirement already satisfied: shortuuid in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 22)) (1.0.13)\nRequirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 23)) (0.32.0.post1)\nRequirement already satisfied: tensorflow>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (2.15.0)\nRequirement already satisfied: torch==2.3.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (2.3.0)\nRequirement already satisfied: torchaudio==2.3.0 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 26)) (2.3.0)\nRequirement already satisfied: transformers>=4.35.2 in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 27)) (4.41.2)\nRequirement already satisfied: transformers_stream_generator in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 28)) (0.0.5)\nRequirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 29)) (0.25.0)\nCollecting vllm (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading vllm-0.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.2 kB)\nRequirement already satisfied: yacs in /opt/conda/lib/python3.10/site-packages (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 31)) (0.1.8)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (3.9.1)\nRequirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (0.27.0)\nRequirement already satisfied: markdown2[all] in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (2.4.13)\nRequirement already satisfied: nh3 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (0.2.18)\nRequirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (3.0.42)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (2.32.3)\nRequirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (13.7.0)\nRequirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (0.4.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from intel_extension_for_pytorch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 8)) (5.9.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from intel_extension_for_pytorch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 8)) (21.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.6.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 16)) (6.0.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.6.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 16)) (4.66.4)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.6.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 16)) (0.4.3)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.13->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 17)) (4.9.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (1.12.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (12.1.105)\nRequirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (2.3.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (12.5.82)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (2.19.2)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (2.2.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (0.70.16)\nRequirement already satisfied: jsonlines in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (4.0.0)\nRequirement already satisfied: numexpr in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (2.10.0)\nRequirement already satisfied: pybind11>=2.6.2 in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (2.12.0)\nRequirement already satisfied: pytablewriter in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (1.2.0)\nRequirement already satisfied: sacrebleu>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (2.4.2)\nRequirement already satisfied: scikit-learn>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (1.2.2)\nRequirement already satisfied: sqlitedict in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (2.1.0)\nRequirement already satisfied: tqdm-multiprocess in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (0.0.11)\nRequirement already satisfied: zstandard in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (0.19.0)\nRequirement already satisfied: word2number in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (1.1)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (10.2.0)\nRequirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (1.2.14)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (4.10.0.82)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (9.5.0)\nRequirement already satisfied: prettytable in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (3.9.0)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (9.0.0)\nRequirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (0.7.7)\nRequirement already satisfied: pycocotools in /opt/conda/lib/python3.10/site-packages (from neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (2.0.8)\nRequirement already satisfied: protobuf>=3.20.2 in /opt/conda/lib/python3.10/site-packages (from onnx>=1.15.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 13)) (3.20.3)\nRequirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 14)) (15.0.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 15)) (0.2.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 15)) (69.0.3)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from optimum-intel->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 15)) (1.11.4)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 20)) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 20)) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 20)) (1.16.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 21)) (2023.12.25)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 21)) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from sacremoses->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 21)) (1.4.2)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 23)) (4.2.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (3.3.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (2.4.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (1.59.3)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24))\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.35.2->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 27)) (0.19.1)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 29)) (0.14.0)\nCollecting cmake>=3.21 (from vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading cmake-3.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (1.11.1.1)\nINFO: pip is looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\nCollecting vllm (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading vllm-0.5.0.post1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.1 kB)\nCollecting openai (from vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading openai-1.35.10-py3-none-any.whl.metadata (21 kB)\nCollecting vllm (from -r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading vllm-0.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.3 kB)\n  Downloading vllm-0.4.3-cp310-cp310-manylinux1_x86_64.whl.metadata (7.8 kB)\n  Downloading vllm-0.4.2-cp310-cp310-manylinux1_x86_64.whl.metadata (9.1 kB)\n  Downloading vllm-0.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.9 kB)\n  Downloading vllm-0.4.0.post1-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\nRequirement already satisfied: ray>=2.9 in /opt/conda/lib/python3.10/site-packages (from vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (2.9.0)\n  Downloading vllm-0.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\nINFO: pip is still looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n  Downloading vllm-0.3.3-cp310-cp310-manylinux1_x86_64.whl.metadata (7.8 kB)\n  Downloading vllm-0.3.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.5 kB)\n  Downloading vllm-0.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n  Downloading vllm-0.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.4 kB)\n  Downloading vllm-0.2.7-cp310-cp310-manylinux1_x86_64.whl.metadata (6.8 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading vllm-0.2.6-cp310-cp310-manylinux1_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: pyarrow in /opt/conda/lib/python3.10/site-packages (from vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (14.0.2)\n  Downloading vllm-0.2.5-cp310-cp310-manylinux1_x86_64.whl.metadata (6.5 kB)\nCollecting xformers>=0.0.23 (from vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting aioprometheus[starlette] (from vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading aioprometheus-23.12.0-py3-none-any.whl.metadata (9.8 kB)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 23)) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 23)) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 23)) (1.2.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.42.0)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (0.6)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->intel_extension_for_pytorch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 8)) (3.1.1)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.0->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (0.2.13)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (4.20.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (1.0.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (2.17.2)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (2.10.0)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.5.0->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (5.2.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.24.1->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (3.2.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (3.0.3)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from aioprometheus[starlette]->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (3.9.10)\nCollecting quantile-python>=1.1 (from aioprometheus[starlette]->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30))\n  Downloading quantile-python-1.1.tar.gz (2.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 14)) (10.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (1.0.5)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (2.1.3)\nRequirement already satisfied: wavedrom in /opt/conda/lib/python3.10/site-packages (from markdown2[all]->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (2.0.3.post3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 4)) (2023.4)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (3.7.5)\nRequirement already satisfied: DataProperty<2,>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (1.0.1)\nRequirement already satisfied: mbstrdecoder<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (1.1.3)\nRequirement already satisfied: pathvalidate<4,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (3.2.0)\nRequirement already satisfied: tabledata<2,>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (1.3.3)\nRequirement already satisfied: tcolorpy<1,>=0.0.5 in /opt/conda/lib/python3.10/site-packages (from pytablewriter->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (0.1.6)\nRequirement already satisfied: typepy<2,>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (1.3.2)\nRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.3.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 25)) (1.3.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (0.6.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (12.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (1.3.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (0.1.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 10)) (1.4.5)\nRequirement already satisfied: chardet<6,>=3.0.4 in /opt/conda/lib/python3.10/site-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 9)) (5.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray>=2.9->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray>=2.9->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (0.32.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray>=2.9->vllm->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 30)) (0.16.2)\nRequirement already satisfied: svgwrite in /opt/conda/lib/python3.10/site-packages (from wavedrom->markdown2[all]->fschat==0.2.35->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 6)) (1.4.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.13.0->-r /kaggle/working/intel-extension-for-transformers/intel_extension_for_transformers/neural_chat/requirements.txt (line 24)) (3.2.2)\nDownloading fschat-0.2.35-py3-none-any.whl (226 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading vllm-0.2.5-cp310-cp310-manylinux1_x86_64.whl (9.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.26.post1-cp310-cp310-manylinux2014_x86_64.whl (222.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading aioprometheus-23.12.0-py3-none-any.whl (31 kB)\nBuilding wheels for collected packages: quantile-python\n  Building wheel for quantile-python (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for quantile-python: filename=quantile_python-1.1-py3-none-any.whl size=3444 sha256=bc4488c96947d206d239d164c7e56778c925db46abe6bd69026abecfd288ab16\n  Stored in directory: /root/.cache/pip/wheels/6d/f4/0a/0e7d01548a005f9f3fa23101f071d248da052f2a9bf2fe11c6\nSuccessfully built quantile-python\nInstalling collected packages: quantile-python, keras, aioprometheus, xformers, fschat, vllm\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: fschat\n    Found existing installation: fschat 0.2.32\n    Uninstalling fschat-0.2.32:\n      Successfully uninstalled fschat-0.2.32\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed aioprometheus-23.12.0 fschat-0.2.35 keras-2.15.0 quantile-python-1.1 vllm-0.2.5 xformers-0.0.26.post1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install huggingface_hub\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:42:25.242477Z","iopub.execute_input":"2024-07-08T10:42:25.242792Z","iopub.status.idle":"2024-07-08T10:42:37.951583Z","shell.execute_reply.started":"2024-07-08T10:42:25.242763Z","shell.execute_reply":"2024-07-08T10:42:37.950661Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.23.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin(token=\"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\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:42:37.952919Z","iopub.execute_input":"2024-07-08T10:42:37.953211Z","iopub.status.idle":"2024-07-08T10:42:38.510200Z","shell.execute_reply.started":"2024-07-08T10:42:37.953184Z","shell.execute_reply":"2024-07-08T10:42:38.509308Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Chatbot with fine tuning in text generation","metadata":{}},{"cell_type":"code","source":"# text-generation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\nfrom intel_extension_for_transformers.neural_chat.config import (\n    ModelArguments,\n    DataArguments,\n    FinetuningArguments,\n    TextGenerationFinetuningConfig,\n)\nfrom intel_extension_for_transformers.neural_chat.chatbot import finetune_model\nmodel_args = ModelArguments(model_name_or_path=\"meta-llama/Llama-2-7b-chat-hf\")\ndata_args = DataArguments(train_file=\"/kaggle/input/alpaka/stanford_alpaca-main/alpaca_data.json\", validation_split_percentage=1)\ntraining_args = TrainingArguments(\n    output_dir='./tmp',\n    do_train=True,\n    do_eval=True,\n    num_train_epochs=3,\n    overwrite_output_dir=True,\n    gradient_accumulation_steps=2\n)\nfinetune_args = FinetuningArguments()\nfinetune_cfg = TextGenerationFinetuningConfig(\n            model_args=model_args,\n            data_args=data_args,\n            training_args=training_args,\n            finetune_args=finetune_args,\n        )\n\n# Fine-tune model\nfinetune_model(finetune_cfg)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:42:38.511312Z","iopub.execute_input":"2024-07-08T10:42:38.511675Z","iopub.status.idle":"2024-07-08T10:46:57.103669Z","shell.execute_reply.started":"2024-07-08T10:42:38.511648Z","shell.execute_reply":"2024-07-08T10:46:57.101898Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n  warn(\n2024-07-08 10:42:51.914752: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-08 10:42:51.914894: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-08 10:42:52.025330: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573a1116431b498991946bd5fc303d60"}},"metadata":{}},{"name":"stderr","text":"[INFO|configuration_utils.py:733] 2024-07-08 10:43:02,370 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/config.json\n[INFO|configuration_utils.py:796] 2024-07-08 10:43:02,374 >> Model config LlamaConfig {\n  \"_name_or_path\": \"meta-llama/Llama-2-7b-chat-hf\",\n  \"architectures\": [\n    \"LlamaForCausalLM\"\n  ],\n  \"attention_bias\": false,\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 4096,\n  \"mlp_bias\": false,\n  \"model_type\": \"llama\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 32,\n  \"pretraining_tp\": 1,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_scaling\": null,\n  \"rope_theta\": 10000.0,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.41.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6532989c39745e59559864a07d1ef33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64a128ff6f2240c281819823838df361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df84d7d4dace4f81b0466fcfe400daf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"817ed276f0be4082a412ded0fd22b052"}},"metadata":{}},{"name":"stderr","text":"[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:43:03,588 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.model\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:43:03,589 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:43:03,589 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/special_tokens_map.json\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:43:03,590 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:43:03,591 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/tokenizer.json\nUsing custom data configuration default-7c3da15835eb6e6d\nLoading Dataset Infos from /opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/json\nGenerating dataset json (/root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7)\nDownloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7...\nDownloading took 0.0 min\nChecksum Computation took 0.0 min\nGenerating train split\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a924c2f74775485cb4a6496ceb41ae93"}},"metadata":{}},{"name":"stderr","text":"Unable to verify splits sizes.\nDataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7. Subsequent calls will reuse this data.\nUsing custom data configuration default-7c3da15835eb6e6d\nLoading Dataset Infos from /opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/json\nOverwrite dataset info from restored data version if exists.\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7\nFound cached dataset json (/root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7)\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7\nUsing custom data configuration default-7c3da15835eb6e6d\nLoading Dataset Infos from /opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/json\nOverwrite dataset info from restored data version if exists.\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7\nFound cached dataset json (/root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7)\nLoading Dataset info from /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b7f3f6f80144ff6acfb9e6956f62003"}},"metadata":{}},{"name":"stderr","text":"[INFO|modeling_utils.py:3474] 2024-07-08 10:43:05,624 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/model.safetensors.index.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9bb00bfc5f4433aa5abe521c83d9c83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98060700bc9f41f982868b146fdef165"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf7d68cbc5244036b92341f37f5e9474"}},"metadata":{}},{"name":"stderr","text":"[INFO|modeling_utils.py:1519] 2024-07-08 10:43:59,693 >> Instantiating LlamaForCausalLM model under default dtype torch.float32.\n[INFO|configuration_utils.py:962] 2024-07-08 10:43:59,697 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"090fbfc86da04c01b473cf3cc36fc857"}},"metadata":{}},{"name":"stderr","text":"[INFO|modeling_utils.py:4280] 2024-07-08 10:44:45,759 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n\n[INFO|modeling_utils.py:4288] 2024-07-08 10:44:45,762 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c11327d080724df6bf5fb14a4eae9831"}},"metadata":{}},{"name":"stderr","text":"[INFO|configuration_utils.py:917] 2024-07-08 10:44:45,962 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--meta-llama--Llama-2-7b-chat-hf/snapshots/f5db02db724555f92da89c216ac04704f23d4590/generation_config.json\n[INFO|configuration_utils.py:962] 2024-07-08 10:44:45,963 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"do_sample\": true,\n  \"eos_token_id\": 2,\n  \"max_length\": 4096,\n  \"pad_token_id\": 0,\n  \"temperature\": 0.6,\n  \"top_p\": 0.9\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/51482 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"516505ec47f145e5b56de81a9c51dad5"}},"metadata":{}},{"name":"stderr","text":"Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-92068497bf215d36.arrow\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/520 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"309f88a870cf45559378d6f156e72dea"}},"metadata":{}},{"name":"stderr","text":"Caching processed dataset at /root/.cache/huggingface/datasets/json/default-7c3da15835eb6e6d/0.0.0/c8d2d9508a2a2067ab02cd118834ecef34c3700d143b31835ec4235bf10109f7/cache-9b9c3942acbb8901.arrow\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n","output_type":"stream"}]},{"cell_type":"code","source":"#chatbot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BF16 Optimization\nfrom intel_extension_for_transformers.neural_chat import build_chatbot, PipelineConfig\nfrom intel_extension_for_transformers.transformers import MixedPrecisionConfig\nconfig = PipelineConfig(optimization_config=MixedPrecisionConfig())\nchatbot = build_chatbot(config)\nresponse1 = chatbot.predict(query=\"What can you tell me about blackhole? Summerize.\")\nprint(response1)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:46:57.105601Z","iopub.execute_input":"2024-07-08T10:46:57.106994Z","iopub.status.idle":"2024-07-08T10:48:46.788726Z","shell.execute_reply.started":"2024-07-08T10:46:57.106961Z","shell.execute_reply":"2024-07-08T10:48:46.787787Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Loading model Intel/neural-chat-7b-v3-1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c6bc71523cf4af28d5c0326efbb0823"}},"metadata":{}},{"name":"stderr","text":"[INFO|configuration_utils.py:733] 2024-07-08 10:46:57,344 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/config.json\n[INFO|configuration_utils.py:796] 2024-07-08 10:46:57,346 >> Model config MistralConfig {\n  \"_name_or_path\": \"Intel/neural-chat-7b-v3-1\",\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 4096,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"float16\",\n  \"transformers_version\": \"4.41.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e89fd4ed42654bcfb961b2367d2d7455"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73c70ab2e19947fe9466db65fcbfd8a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a55c5aafb34845c38a0a7f12875ba852"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/145 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c48f5e2fe57f4e5e9f5eb24bb769f518"}},"metadata":{}},{"name":"stderr","text":"[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:46:58,327 >> loading file tokenizer.model from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/tokenizer.model\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:46:58,328 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/tokenizer.json\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:46:58,329 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:46:58,330 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/special_tokens_map.json\n[INFO|tokenization_utils_base.py:2108] 2024-07-08 10:46:58,330 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/tokenizer_config.json\n[INFO|configuration_utils.py:733] 2024-07-08 10:46:58,610 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/config.json\n[INFO|configuration_utils.py:796] 2024-07-08 10:46:58,612 >> Model config MistralConfig {\n  \"_name_or_path\": \"Intel/neural-chat-7b-v3-1\",\n  \"architectures\": [\n    \"MistralForCausalLM\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 4096,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 14336,\n  \"max_position_embeddings\": 32768,\n  \"model_type\": \"mistral\",\n  \"num_attention_heads\": 32,\n  \"num_hidden_layers\": 32,\n  \"num_key_value_heads\": 8,\n  \"rms_norm_eps\": 1e-05,\n  \"rope_theta\": 10000.0,\n  \"sliding_window\": 4096,\n  \"tie_word_embeddings\": false,\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.41.2\",\n  \"use_cache\": true,\n  \"vocab_size\": 32000\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a91257061e04303930458cf8c526fe0"}},"metadata":{}},{"name":"stderr","text":"[INFO|modeling_utils.py:3474] 2024-07-08 10:46:58,936 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/model.safetensors.index.json\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ced0649971c648caa0c9051b7a65b8cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"974b337a5be34b23bf722f8697a1a68e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8107dfbad0f49b78c7877e520d6cf21"}},"metadata":{}},{"name":"stderr","text":"[INFO|modeling_utils.py:1519] 2024-07-08 10:48:02,494 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n[INFO|configuration_utils.py:962] 2024-07-08 10:48:02,498 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3943e6ecd57409e8ab3ce2d94dbf451"}},"metadata":{}},{"name":"stderr","text":"[INFO|modeling_utils.py:4280] 2024-07-08 10:48:28,053 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n\n[INFO|modeling_utils.py:4288] 2024-07-08 10:48:28,056 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at Intel/neural-chat-7b-v3-1.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b066b4406d86448fb8f34f476b7aca5f"}},"metadata":{}},{"name":"stderr","text":"[INFO|configuration_utils.py:917] 2024-07-08 10:48:28,272 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Intel--neural-chat-7b-v3-1/snapshots/c0d379a49c1c0579529d5e6f2e936ddb759552a8/generation_config.json\n[INFO|configuration_utils.py:962] 2024-07-08 10:48:28,274 >> Generate config GenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2\n}\n\n","output_type":"stream"},{"name":"stdout","text":"A black hole is a region in space where gravity is so strong that nothing, not even light, can escape its pull. It forms when a massive star collapses at the end of its life, leaving behind only its dense core. Black holes come in different sizes, from stellar-mass ones formed by stars to supermassive ones found at the centers of galaxies. They play a significant role in shaping the universe's structure and evolution. In summary, black holes are mysterious cosmic phenomena with immense gravitational force, created through the collapse of massive stars or other celestial objects. they continue to fascinate scientists and inspire curiosity about our vast universe. they are part of the natural cycle of stellar life, contributing to the formation and growth of galaxies. они remind us of the incredible power and complexity of nature. they teach us about the limits of our understanding and push the boundaries of scientific knowledge. they serve as a reminder of the beauty and mystery of the universe we inhabit. they challenge our perception of reality and invite us to explore the unknown. they are both terrifying and awe-inspiring, reminding us of the fragility of existence within their grasp.\n","output_type":"stream"}]},{"cell_type":"code","source":"response2 = chatbot.predict(query=\"Is God really one?\")\nprint(response2)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:48:46.791334Z","iopub.execute_input":"2024-07-08T10:48:46.792072Z","iopub.status.idle":"2024-07-08T10:48:58.464088Z","shell.execute_reply.started":"2024-07-08T10:48:46.792033Z","shell.execute_reply":"2024-07-08T10:48:58.463140Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Is God truly one? This question has been debated throughout history, with various interpretations and beliefs. Some religions teach about a single, all-encompassing deity, while others believe in multiple gods or goddesses. Ultimately, it's up to each individual to find their own understanding of divinity and spirituality. In the end, what matters most is how we treat one another, fostering love, compassion, and unity among all beings. целеспрямованість людського життя. целеспрямованість людського життя. целеспрямованість людського життя. целеспрямованість людського життя. целеспрямованість людського життя.інде целеспрямованість людського життя.інде целеспрямованість людського життя.інде целеспрямованість людського життя.інде целеспрямованість людського життя.\n","output_type":"stream"}]},{"cell_type":"code","source":"response3 = chatbot.predict(query=\"Do Aliens Exist?\")\nprint(response3)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:48:58.468210Z","iopub.execute_input":"2024-07-08T10:48:58.468884Z","iopub.status.idle":"2024-07-08T10:49:11.061116Z","shell.execute_reply.started":"2024-07-08T10:48:58.468855Z","shell.execute_reply":"2024-07-08T10:49:11.060168Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The universe is vast and mysterious, filled with wonders we have yet to discover. While there's no concrete evidence proving the existence of extraterrestrial life, it's important to keep an open mind about the possibility. Some scientists believe that given the sheer number of stars and planets in our galaxy alone, it's highly likely that other forms of intelligent life exist somewhere out there. However, without tangible proof or contact, this remains a fascinating topic for debate and speculation. In the end, only time and further exploration can truly reveal the truth behind the question, \"Do Aliens Exist?\" індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember індеcember ін\n","output_type":"stream"}]},{"cell_type":"code","source":"response4 = chatbot.predict(query=\"What do you think about yoga?\")\nprint(response4)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:49:11.062231Z","iopub.execute_input":"2024-07-08T10:49:11.062540Z","iopub.status.idle":"2024-07-08T10:49:23.635511Z","shell.execute_reply.started":"2024-07-08T10:49:11.062511Z","shell.execute_reply":"2024-07-08T10:49:23.634571Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Yoga is a beautiful practice that combines physical postures, breathing techniques, and meditation to promote overall well-being. It has been around for thousands of years and continues to evolve with time. By embracing yoga, one can experience increased flexibility, mental clarity, stress relief, and improved self-awareness. So, I believe it's a wonderful way to nurture both body and mind. Namaste. інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде інде\n","output_type":"stream"}]},{"cell_type":"code","source":"response5 = chatbot.predict(query=\"Can by any means we acheive superpowers? If yes how?\")\nprint(response5)","metadata":{"execution":{"iopub.status.busy":"2024-07-08T10:49:23.636760Z","iopub.execute_input":"2024-07-08T10:49:23.637058Z","iopub.status.idle":"2024-07-08T10:49:36.018904Z","shell.execute_reply.started":"2024-07-08T10:49:23.637030Z","shell.execute_reply":"2024-07-08T10:49:36.017968Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Yes, in some ways, we can achieve superpowers. These powers may not be as dramatic as those found in comics or movies, but they can still enhance our abilities. Here's how:\n\n1. Mental strength: Developing mental resilience, focus, and self-discipline can give us a sense of control over our thoughts and emotions, making us feel like we have a certain level of \"mental power.\"\n\n2. Physical fitness: Regular exercise and proper nutrition can improve our overall health and well-being, leading to increased energy levels and better physical performance. This can make us feel more capable and powerful.\n\n3. Learning new skills: Acquiring new talents and knowledge can broaden our horizons and open up opportunities for personal growth. This can lead to a feeling of empowerment and accomplishment.\n\n4. Embracing creativity: Engaging in creative activities such as writing, painting, or music can help us tap into our inner potential and express ourselves in unique ways. This can provide a sense of freedom and self-expression.\n\n5. Connecting with others: Building strong relationships and supporting one another can create a sense of community and belonging.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Human Conversation\nwhile True:\n    query = input('USER: ')\n    if query.lower() == 'thank you':\n        print('CHATBOT: Let me know if there is anything else that I can help you with... THANK YOU !')\n        break\n    response = chatbot.predict(query=query)\n    print(f'CHATBOT: {response}')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T11:17:41.425187Z","iopub.execute_input":"2024-07-08T11:17:41.425664Z","iopub.status.idle":"2024-07-08T11:18:39.596906Z","shell.execute_reply.started":"2024-07-08T11:17:41.425619Z","shell.execute_reply":"2024-07-08T11:18:39.595939Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdin","text":"USER:  Hi, How are you?\n"},{"name":"stdout","text":"CHATBOT: I am doing great, thank you for asking! It's wonderful to connect with others and share our well-being. Let's spread positivity together. 😊🌈 вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре вре\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"USER:  thank you\n"},{"name":"stdout","text":"CHATBOT: Let me know if there is anything else that I can help you with... THANK YOU !\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
